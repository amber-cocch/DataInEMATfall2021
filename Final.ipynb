{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7ac209a",
   "metadata": {},
   "source": [
    "# Ao3 Tags on \"Fix-it Fics\" as an Indicator of Satisfying Endings #\n",
    "\n",
    "Are there common themes among fix it fics that show what audiences crave that shows lack? To answer this, I will scrape data from Archive of Our Own (Ao3) to compare tags used on “fix it” fanfictions, or fanfictions that aim to give the show a “better” ending, across the shows Voltron, Supernatural, and Star Wars: The Sequel Trilogy. The answer to this question could be used to suggest what themes audiences are wanting to see in media in general and could be used as a recommendation to media writers on how to create “satisfying” endings. \n",
    "\n",
    "\n",
    "## Data Collection ##\n",
    "\n",
    "To do this, I will use the following packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdfff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import json\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13df93c8",
   "metadata": {},
   "source": [
    "I request data from Ao3 using the requests library. I did some work on Ao3's actual page as it would be easier than generate the url, which I was unsure how to do. There is not a lot of documentation on how Ao3 works, as seen by the lack of API, so all urls will be generated on the actual Ao3 site and then pasted over.\n",
    "\n",
    "\n",
    "\n",
    "### Playing with the Data ###\n",
    "\n",
    "I wanted to see how to scrape Ao3, so I used Voltron as a test. I obtained the website url to scrape from by doing a manual search on Ao3's website. Ao3 lists 20 fanfics per page, so this will have 20 fanfics worth of tags. Tags are not limited, so this is entirely dependent on what the author decided to list when publishing the fic. I also decided to exclude any explicit labeled fanfictions for the sake of this being a school project and having to present this data. This works out for the overall mission as well, as all of the fandoms I chose are aired on TV and follow FCC guidelines on how graphic their content can be for TV-14/PG-13."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a22d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.request(\"GET\", 'https://archiveofourown.org/tags/Voltron:%20Legendary%20Defender/works?commit=Sort+and+Filter&exclude_work_search%5Brating_ids%5D%5B%5D=13&page=1&utf8=%E2%9C%93&work_search%5Bcomplete%5D=&work_search%5Bcrossover%5D=&work_search%5Bdate_from%5D=&work_search%5Bdate_to%5D=&work_search%5Bexcluded_tag_names%5D=&work_search%5Blanguage_id%5D=&work_search%5Bother_tag_names%5D=Fix-It&work_search%5Bquery%5D=&work_search%5Bsort_column%5D=revised_at&work_search%5Bwords_from%5D=&work_search%5Bwords_to%5D=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b6c636",
   "metadata": {},
   "outputs": [],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74549d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs(page.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66dbd38",
   "metadata": {},
   "source": [
    "I looked through the soup in order to find what html tags contained the \"tag\" items that I will need for my analysis. In this case, it is in linked items (<a/href>) with the class \"tag\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924ac53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a767d5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = soup.find_all('a', class_='tag')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c10e74",
   "metadata": {},
   "source": [
    "With this, I can clean up the list so it just contains what is inside the tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce9030e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4912fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagList = [x.text for x in soup.find_all('a', class_='tag')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828e9dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c52fe2c",
   "metadata": {},
   "source": [
    "And with that, I have a list of tags for the first 20 fix-it fanfics from Voltron in Ao3. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdb198d",
   "metadata": {},
   "source": [
    "### Function Creation ###\n",
    "Now that I have learned how to scrape the tags from Ao3, I will create a function that can take the fandom name, a data frame, and how many pages to iterate through as parameters and spit out a data frame of tags for that fandom. The function can be used as long as you use the exact phrase used for the fandom as Ao3 does. If it is your first time using the function, use an empty data frame. In order to keep appending onto that data frame, feed that same data frame into the function when using a different fandom title. The function will a dataframe with two columns: one with the tags and the other with the name of the fandom that tag came from.\n",
    "\n",
    "The first part of the function is where the showName is changed so the spaces are replaced with \"%20\", as that is how the url reads spaces. The function updates the showName and then iterates through each page requested, scraping tags from each page. It then goes back through to add the final column of the \"Fandom\" is came from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef60ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTags(showName, df, getPages):\n",
    "    pageNum = 1\n",
    "    x = 0\n",
    "    showNameParse = showName.split()\n",
    "    showNameAddSpace = \"\"\n",
    "    for word in showNameParse:\n",
    "        showNameAddSpace = showNameAddSpace + showNameParse[x] + \"%20\"\n",
    "        x += 1\n",
    "    print(showNameAddSpace)\n",
    "    while pageNum < getPages:\n",
    "        page = requests.request(\"GET\", \"https://archiveofourown.org/tags/\" + showNameAddSpace + \"/works?commit=Sort+and+Filter&exclude_work_search%5Brating_ids%5D%5B%5D=13&page=\" + str(pageNum) + \"&utf8=%E2%9C%93&work_search%5Bcomplete%5D=&work_search%5Bcrossover%5D=&work_search%5Bdate_from%5D=&work_search%5Bdate_to%5D=&work_search%5Bexcluded_tag_names%5D=&work_search%5Blanguage_id%5D=&work_search%5Bother_tag_names%5D=Fix-It&work_search%5Bquery%5D=&work_search%5Bsort_column%5D=revised_at&work_search%5Bwords_from%5D=&work_search%5Bwords_to%5D=\")\n",
    "        soup = bs(page.text, \"html.parser\")\n",
    "        tagList = [x.text for x in soup.find_all('a', class_='tag')]\n",
    "        pageNum += 1\n",
    "        if df.empty:\n",
    "            df = df.append(tagList)\n",
    "        else:\n",
    "            df = df.append(tagList)\n",
    "        for x in df:\n",
    "            df[\"Fandom\"] = showName\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f0fda5",
   "metadata": {},
   "source": [
    "### Voltron ###\n",
    "\n",
    "I chose Voltron for this project due to its notoriety of having a disliked ending by the fans. I will use my function to obtain the tags from the first 5 pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3924145d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_df = pd.DataFrame()\n",
    "final_tagList = getTags(\"Voltron: Legendary Defender\", tag_df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7dc83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tag_df.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433f2ba1",
   "metadata": {},
   "source": [
    "### Supernatural ###\n",
    "\n",
    "Now that I have 40 fanfics worth of tags for Voltron, I will repeat this process for the tv show Supernatural, chosen for its popularity as the subject of fanfiction (over 240,000 fics!) and for its bad ending. \n",
    "\n",
    "Since I have already worked out what tags I need and how I can get them from this site, I will be condensing my process to fewer cells with less explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66a73e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tagList = getTags(\"Supernatural\", final_tagList, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b6e4f3",
   "metadata": {},
   "source": [
    "### Star Wars: The Sequel Trilogy ###\n",
    "\n",
    "This fandom is different than the previous two chosen as it is much bigger than Voltron or even Supernatural since it encompasses many different movies and tv shows. When I chose Star Wars, I did so because I personally did not like the ending to Star Wars Episode IX Rise of Skywalker. I did a preliminary check and found fix-it fanfics for that movie. However, when choosing which fandom website to sort and scrape, I found that there were 11 categories for the Star Wars media franchise. Rather than look through all of the media, which was a category, I chose to stay true to what made me pick Star Wars in general and chose the \"Star Wars: The Sequel Trilogy\" fandom since it includes Rise of Skywalker.\n",
    "\n",
    "Despite this being a movie trilogy rather than a tv show, I do not expect this media difference to affect tag usage and preferences among fix-it fanfics. \n",
    "\n",
    "Since I have already worked out what tags I need and how I can get them from this site, I will be condensing my process to fewer cells with less explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efde540",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tagList = getTags(\"Star Wars Sequel Trilogy\", final_tagList, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0094eb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tagList"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
